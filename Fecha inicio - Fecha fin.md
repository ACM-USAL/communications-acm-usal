<!--¿Fecha: 15 de enero-31 de enero?-->
#The fracking best balatin
##Angry Birds AI Competition
![Angry Birds AI Competition](https://aibirds.org/images/banners/aibirds.png)

Sí, existe. Su objetivo es desarrollar el mejor agente capaz de jugar al Angry Birds y 2015 será su cuarto año. Es sencillo, el programa tiene que ver la pantalla, decidir los movimientos y ejecutarlos. Pero sorpresa, no fueron capaces de derrotar a un humano (por mucho).

Este es el ganador de 2014: https://www.youtube.com/watch?v=8RWo8LCgJPc

Y estáis a tiempo de apuntaros a la edición de este año: https://aibirds.org

##Talking Machines: Machine Learning podcast
![Talking Machines](http://static1.squarespace.com/static/54a56ccbe4b0ab38fed9fc81/t/54a56d1fe4b0c309d01404ce/1421332685021/?format=1500w)

Si te gustó la charla de [redes neuronales que tuvimos](https://www.youtube.com/watch?v=yN3bPRHLd5s) seguro que quieres seguir el nuevo podcast sobre machine learning ["Talking Machines"](http://www.thetalkingmachines.com). Ya van dos episodios e intervienen varios pesos pesados del campo.

Aquí tenéis los episodios: http://www.thetalkingmachines.com/

Y si escuchar en guiri no es lo vuestro [aquí tenéis una transcripción](http://pastebin.com/N3RuPQ8c). Por supuesto ha sido creada con [reconocimiento automático de voz](http://www.reddit.com/r/MachineLearning/comments/2r5cuq/talkingmachines_a_new_podcast_featuring/cnd1h0p).

##Nuevo récord mundial en ordenación de datos
![Apache Spark](http://docs.sigmoidanalytics.com/images/c/ce/Sparkimage.png)

El equipo de Databricks participó en la última competición de [Sort Benchmark](http://sortbenchmark.org/) utilizando Apache Spark y una infraestructura en la nube utilizando [Amazon Elastic Cloud](http://aws.amazon.com/ec2/).

Apache Spark, el llamado sucesor de Hadoop MapReduce hace justicia a su nombre, ordenando 100 terabytes de datos en 23 minutos, reduciendo en más de la mitad el tiempo de ordenación requerido por MapReduce (72 minutos).

Los chicos de opensource.com han hecho una comparativa exhaustiva de ambos competidores y detallan el proceso de creación de la infraestructura necesaria para batir este record. Puedes encontrar más [aquí](http://opensource.com/business/15/1/apache-spark-new-world-record).
